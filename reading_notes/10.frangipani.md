# Frangipani: A Scalable Distributed File System

## PASS-1

+ *Category*:
    + distributed file system prototype
+ *Context*:
    + *Petal*: distributed storage service with virtual disk
+ *Correctness*
+ *Contributions*:
    + manage disks as a single shared pool storage
    + two-layer structure
        1. Petal -> distributed storage service
        2. file system instances and lock service
    + new internal structure: a set of cooperating machines use a common store and synchronize access to that store with locks
+ *Clarity*:
    + System structure
    + Disk layout
    + Logging and Recovery
    + Synchronization and cache recovery
    + Lock service
    + adding and removing servers
    + backup
    + performance

## PASS-2

### System Structure

+ interchangeable Frangipani file server module
  + 不同Frangipani文件系统模块共享整个虚拟磁盘
+ petal device driver
  + file server通过petal驱动访问虚拟磁盘
+ Lock server
  + 分布式锁服务器，每个锁管理对应lockable segment
+ petal server

### 磁盘布局

+ petal提交物理空间用于虚拟磁盘使用的最小单位是64kb
+ 0-1T：配置参数
+ 1T-2T: 放置每个file server对应日志
+ 2T-5T：方式bitmaps，每个file server有自己对应的bitmap
+ 5T-6T：inode，以一个磁盘block（512字节）为单位
+ 6T-134T：每4kB作为small blocks
+ 之后每T用于large blocks

### logging and recovery

+ 对metadata使用WAL，不log用户数据
    + log record写入petal之后，server才能修改metadata

#### *故障检测*

1. failed server的客户端检测到故障
2. lock service请求failed server返回锁但没有收到响应

#### *故障恢复*

1. 恢复进程隐式获取failed server的日志和锁
2. 从log start到end，redo没有完成的log
3. 完成后，释放锁和log空间，新的server可以推进

+ note：底层petal available的情况下，任意数量file server故障都能容忍

#### 保证同一log出现多次不影响

1. Frangipani的locking协议保证不同file server对相同数据的更新请求串行化
    + *对任意给定的block至多只有一个未完全应用的log*
2. Frangipani确保recovery仅应用已经logged的更新
    + *利用version number保证不redo已经应用的log*
    + *保证用于metadata的block只用于metadata，这样version number不会丢失*
3. Frangipani确保任意时刻至多只有一个尝试redo log

### synchronization and cache coherence

+ 读写锁实现同步，写锁释放前flush脏数据
+ 两阶段锁协议: 首先按序获得所有可能需要的锁，执行操作，最后统一释放获取的所有锁
+ *锁粒度*：保证单个磁盘sector不会包括超过一个共享数据
    + each log is a single lockable segment
    + bitmap space divided into segments that are locked exclusively
    + each file, directory or symbolic link is one segment(单个lock保护inode即其中的数据)

### the lock service

+ 分布式锁服务器，其客户端是file server
    1. 单一锁服务器 + 本地mem
    2. primary/backup + petal storage
    3. (final)分布式锁服务器，同时每个file server链接一个clerk module
+ 利用lease租约解决client的故障
    + *回忆*：lease租约使得follower支持处理读请求的能力
+ 以table的形式组织锁，每一个文件系统都有一个关联的table和对应的identifier
    + 租约内通过identifier发布请求 

### adding and removing servers

#### adding

+ 需要管理员配置新文件服务器对应的petal virtual disk以及lock service的位置。新file server连接lock service获取租约和identifier。

#### removing

+ 直接crash退出frangipani也能保证安全性。

### backup

+ crash-consistent: a snapshot reflects a coherent state, one that the Petal virtual disk could have been left in if all the Frangipani servers were to crash
+ back up program使用全局锁迫使所有file server等在barrier上，之后进行snapshot

### 一些没想明白的问题

1. 哪些情况会导致log出现多次，可能会导致哪些问题

## Question

> Suppose a server modifies an i-node, appends the modification to its log, then another server modifies the same i-node, and then the first server crashes. The recovery system will see the i-node modification in the crashed server's log, but should not apply that log entry to the i-node, because that would un-do the second server's change. How does Frangipani avoid or cope with this situation?

+ Frangipani use lock to avoid this situation, every time when a server try to modify/write the metadata, it should grab the corresponding lock first, and before it releases the lock it should flush the dirty data to petal. Therefore, since the second server has changed the metadata, it means that it has already grabed the lock of the i-node and the modification caused by the first server has already applied to the storage. So the recovery system should not apply that log entry to the i-node. In order to distinguish those log already applied, Frangipani use a version number for each metadata block, and when recovering only redo those less than the log record version number.
